# Bird Call UMAP - 試行錯誤プロジェクト 🐦
<img width="800" height="600" alt="UMAP 3kHz以上" src="https://github.com/user-attachments/assets/5c9b5964-8775-444e-88cf-07e2e3d56f79" />　

このプロジェクトは、鳥の鳴き声を機械学習とUMAPを用いてクラスタリング・可視化を試みる**実験作品**です。  
Copilot との協働です。作者に専門知識はなくあくまで趣味としてのプロジェクトです。

## 概要

WAVファイルから鳥の鳴き声を自動抽出し、MFCCなどの音響特徴量を用いてクラスタリングを行い、UMAPで2次元空間に可視化します。

## 主な機能（開発中）

- **音声ファイルの選択**: ファイルダイアログでWAVファイルを選択
- **前処理**:
  - ハイパスフィルタ（3000Hz以上）で高周波成分を抽出
  - 音声区間の自動検出（無音区間の除去）
  - **NEW**: 非鳥類音声の除外（人の声、環境音、エアコン、扇風機、ガラス音など）
  - **NEW**: 強化された無音検出（振幅、エネルギー、ゼロ交差率の複合判定）
- **特徴抽出**: MFCC（メル周波数ケプストラム係数）の計算
- **クラスタリング**: K-Meansによる教師なし学習
- **可視化**:
  - UMAPを用いた2次元マッピング
  - スペクトログラムの表示
  - クラスタごとの代表的な鳴き声の可視化
- **音声ファイルの出力**: クラスタごとに代表的な鳴き声セグメントをWAV形式で保存

## 環境構築

### 必要なライブラリ

```bash
pip install librosa matplotlib numpy scikit-learn umap-learn soundfile scipy
```

### 推奨環境

- Python 3.8以上
- tkinter（Pythonに付属）

## 使用方法

```bash
python nakigoe.py
```

実行するとファイル選択ダイアログが開きます。分析対象のWAVファイルを選択してください。

## 出力

- **cluster_segments/** ディレクトリ: クラスタごとの代表的な鳴き声セグメント（WAV形式）
- **UMAP可視化**: クラスタ分布の2次元プロット
- **スペクトログラム**: 各クラスタの代表的な鳴き声の時間周波数解析
- **コンソール出力**: 各クラスタに含まれるフレームの時間情報

## 現在の試行錯誤・課題 ⚠️

このプロジェクトはまだ開発初期段階です。以下のような改善が検討されています：

### パラメータの調整が必要
- **ハイパスフィルタの周波数**: 現在は3000Hzで固定。鳥の種類によって最適値が異なる可能性
- **音声区間検出（top_db値）**: 現在45で固定。環境ノイズレベルに応じた動的調整が必要
- **フレーム長・ホップ長**: 0.2秒で固定。より短い周期での分析が必要な場合も検討中
- **K-Meansのクラスタ数（k=4）**: 最適値の検証が必要
- **MFCC係数数（n_mfcc=20）**: 最適値の検証が必要

### 既知の問題
- パラメータを手動で変更する必要がある（設定ファイル化を検討中）
- 単一ファイルの分析のみに対応（複数ファイルの一括処理未実装）
- 出力ファイルの重複上書きの問題あり
- クラスタの有意性評価がない
- 非鳥類音声フィルタのパラメータは実験的な値であり、録音環境により調整が必要な場合があります
  - パラメータは `nakigoe.py` の11〜22行目で定義されています（`MIN_SPECTRAL_CENTROID_HZ`, `MIN_ZERO_CROSSING_RATE` など）

## 注意事項

- このコードは**実験段階**です
- パラメータ調整には試行錯誤が必要です
- 鳥の種類や録音環境によって結果が大きく変わる可能性があります

## 技術の説明 📚

このプロジェクトで使用されている主要な技術について説明します。

### 非鳥類音声の除外 🎯

**NEW**: 鳥の声を他の音から区別するために、複数の音響特徴量を使用してフィルタリングを行います。

#### 使用する特徴量

1. **ゼロ交差率（Zero Crossing Rate）**
   - 音波が0を横切る頻度を測定
   - 鳥の声は高周波成分が多いため、ゼロ交差率が高い傾向
   - 低い値は持続的な低音ノイズ（エアコン、扇風機など）を示す

2. **スペクトル重心（Spectral Centroid）**
   - 周波数スペクトルの「重心」を計算
   - 鳥の声は高周波に集中するため、重心が高い（2500Hz以上）
   - 人の声や低周波環境音は重心が低い

3. **スペクトルロールオフ（Spectral Rolloff）**
   - エネルギーの85%が含まれる周波数を測定
   - 鳥の声は高周波にエネルギーが集中
   - 低い値は低周波ノイズを示す

4. **RMSエネルギー（Root Mean Square Energy）**
   - 音のエネルギーレベルを測定
   - 極端に低い値はノイズレベルを示す

5. **スペクトルフラックス（Spectral Flux）**
   - 周波数スペクトルの時間的変化を測定
   - 鳥の声は変化に富むため、値が高い傾向

#### フィルタリング基準

以下の条件を満たさない音声区間は除外されます：
- スペクトル重心が2500Hz未満（人の声、低周波ノイズ）
- ゼロ交差率が0.1未満（持続的な低音）
- RMSエネルギーが0.005未満（ノイズレベル）
- スペクトルロールオフが3500Hz未満（低周波支配的な音）

### 強化された無音検出 🔇

フレームレベルでの無音検出を3つの基準で強化：

1. **振幅ベースの判定**: 最大振幅が0.01未満
2. **エネルギーベースの判定**: 平均エネルギーが0.0001未満
3. **ゼロ交差率での判定**: ゼロ交差率が0.05未満（DCノイズ検出）

これらの複合判定により、より正確に無音区間を除外します。

### MFCC（メル周波数ケプストラム係数）とは？

**MFCCは、音の特徴を人間の耳の聞き方に合わせて抽出する技術**です。

- 例えるなら：人間は低い音の違いには敏感ですが、高い音の細かい違いには鈍感です。MFCCはこの人間の聴覚特性を模倣して、音を数値化します。
- 鳥の鳴き声分析では、MFCCを使うことで、鳴き声の音質的な違いを効率的に捉えることができます。

### K-Means（K平均クラスタリング）とは？

**K-Meansは、似たもの同士を自動的にグループ分けする方法**です。

- 例えるなら：100個のボールが机の上に散らばっていて、色が似たもの同士を4つのグループに分ける作業をK-Meansが自動でやってくれます。
- このプロジェクトでは、MFCCで抽出した鳴き声の特徴を基に、似た特徴を持つ鳴き声を同じグループ（クラスタ）にまとめます。

### UMAP（ユニフォーム マニフォールド アプロキシメーション アンド プロジェクション）とは？

**UMAPは、複雑で高次元のデータを、2次元や3次元の簡単な形に圧縮して見やすく表示する技術**です。

- 例えるなら：複数の教科（数学、国語、理科など）の成績という高次元データを、「理系度」と「文系度」の2つの軸で表現するようなイメージです。
- このプロジェクトでは、MFCCで抽出した多くの特徴（高次元データ）をUMAPで2次元にまとめることで、クラスタの分布を視覚的に理解しやすくしています。

## 参考資料

- [librosa - Music and Audio Analysis](https://librosa.org/)
- [UMAP - Uniform Manifold Approximation and Projection](https://umap-learn.readthedocs.io/)
- [scikit-learn - K-Means Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)

## ライセンス

このプロジェクトは MIT ライセンスで公開されています。詳細は [LICENSE](LICENSE) をご覧ください。  
This project is released under the MIT License. See [LICENSE](LICENSE) for details.


## 貢献

このプロジェクトはまだ試行錯誤の段階のため、フィードバックやご提案をお待ちしています.
